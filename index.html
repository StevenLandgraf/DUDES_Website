<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
<meta name="description" content="DUDES introduces a simple and efficient approach for predictive uncertainty estimation in semantic segmentation using student-teacher distillation with Deep Ensembles. It captures reliable uncertainties with a single forward pass.">
<meta property="og:title" content="DUDES: Deep Uncertainty Distillation using Ensembles for Semantic Segmentation"/>
<meta property="og:description" content="We present DUDES, an efficient uncertainty quantification method for semantic segmentation that distills Deep Ensemble uncertainties into a single student model via distillation, combining simplicity, adaptability, and strong performance."/>
  <meta property="og:url" content="https://stevenlandgraf.github.io/DUDES_Website/"/>
  <meta property="og:image" content="static/images/icon.png" />
  <meta property="og:image:width" content="512"/>
  <meta property="og:image:height" content="512"/>

  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="semantic segmentation, uncertainty estimation, deep ensembles, student-teacher distillation, deep learning, model calibration, Cityscapes, Pascal VOC, out-of-domain detection, DUDES">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>DUDES: Deep Uncertainty Distillation using Ensembles for Semantic Segmentation</title>
  <link rel="icon" type="image/x-icon" href="static/images/icon.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">DUDES: Deep Uncertainty Distillation using Ensembles for Semantic Segmentation</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=7DOqcXkAAAAJ&hl=en" target="_blank">Steven Landgraf</a><sup>*</sup>,</span>
                <span class="author-block">
                  <a href="https://scholar.google.com/citations?user=P8p0BNcAAAAJ&hl=de" target="_blank">Kira Wursthorn</a>,</span>
                <span class="author-block">
                  <a href="https://scholar.google.com/citations?user=_qfDWfUAAAAJ&hl=en" target="_blank">Markus Hillemann</a>,</span>
                  <span class="author-block">
                    <a href="https://scholar.google.com/citations?user=JutLoKsAAAAJ&hl=en" target="_blank">Markus Ulrich</a>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Machine Vision Metrology (MVM)<br>Institute of Photogrammetry and Remote Sensing (IPF)<br>Karlsruhe Institute of Technology (KIT)<br> PFG Journal of Photogrammetry, Remote Sensing and Geoinformation Science [2024]</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Corresponding Author</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- PDF link -->
                      <span class="link-block">
                        <a href="https://link.springer.com/article/10.1007/s41064-024-00280-4" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>
                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/StevenLandgraf/DUDES" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            The intersection of deep learning and photogrammetry unveils a critical need for balancing the power of deep neural networks with interpretability and trustworthiness, 
            especially for safety-critical application like autonomous driving, medical imaging, or machine vision tasks with high demands on reliability. 
            Quantifying the predictive uncertainty is a promising endeavour to open up the use of deep neural networks for such applications. 
            Unfortunately, most current available methods are computationally expensive. In this work, we present a novel approach for efficient and reliable uncertainty estimation for semantic segmentation, 
            which we call Deep Uncertainty Distillation using Ensembles for Segmentation (DUDES). DUDES applies student-teacher distillation with a Deep Ensemble 
            to accurately approximate predictive uncertainties with a single forward pass while maintaining simplicity and adaptability. 
            Experimentally, DUDES accurately captures predictive uncertainties without sacrificing performance on the segmentation task and indicates impressive capabilities of highlighting wrongly classified pixels 
            and out-of-domain samples through high uncertainties on the Cityscapes and Pascal VOC 2012 dataset. With DUDES, we manage to simultaneously simplify and outperform previous work on Deep-Ensemble-based Uncertainty Distillation.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item">
          <!-- Center and resize the image -->
          <div class="has-text-centered">
            <img src="static/images/methodology.png" alt="MY ALT TEXT" style="max-width: 85%; height: auto;" />
          </div>
          <h2 class="subtitle has-text-centered">
            A schematic overview of the training process of the student model of DUDES. DUDES is an easy-to-adapt framework for efficiently estimating predictive uncertainty through student-teacher distillation. 
            The student model simultaneously outputs a segmentation prediction alongside a corresponding uncertainty prediction. 
            Training the student involves a regular segmentation loss with the ground truth labels and an additional uncertainty loss. 
            As ground truth uncertainties, we compute the predictive uncertainty of a Deep Ensemble, thereby acting as the teacher.
          </h2>
        </div>
        <div class="item">
          <div class="has-text-centered">
            <img src="static/images/uncertain_pixels_removed.png" alt="MY ALT TEXT" style="max-width: 85%; height: auto;" />
          </div>
          <h2 class="subtitle has-text-centered">
            Comparison between the student's and the teacher's mean Intersection over Union (mIoU). We progressively ignore an increasing percentage of pixels in the segmentation prediction
             and simultaneously re-evaluated the mIoU. The pixels are sorted based on their predictive uncertainty in descending order, thus removing the most uncertain segmentation predictions first.
          </h2>
        </div>
        <div class="item">
          <div class="has-text-centered">
            <img src="static/images/Qualitative_Examples.png" alt="MY ALT TEXT" style="max-width: 85%; height: auto;" />
          </div>
          <h2 class="subtitle has-text-centered">
            Example images from the Cityscapes validation set (a) with corresponding ground truth labels (b), our student's segmentation predictions (c), a binary accuracy map (d), 
            and the student's uncertainty prediction (e). White pixels in the binary accuracy map are either incorrect predictions or void classes. 
            Latter appear black in the ground truth labels. For the uncertainty prediction, brighter pixels represent higher predictive uncertainties
          </h2>
        </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->

<!-- Paper Conclusion -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Conclusion</h2>
        <div class="content has-text-justified">
          <p>
            In this work, we propose DUDES, an efficient and reliable uncertainty quantification method by applying student-teacher distillation that maintains simplicity and adaptability throughout the entire framework. 
            We quantitatively demonstrated that DUDES accurately captures predictive uncertainties without sacrificing performance on the segmentation task. 
            Additionally, qualitative results indicate impressive capabilities for the potential identification of wrongly classified pixels and out-of-domain samples through a simple uncertainty-based threshold. 
            With DUDES, we managed to simultaneously simplify and outperform previous work on Deep-Ensemble-based uncertainty quantification.

            We hope that DUDES encourages other researchers to incorporate uncertainties into state-of-the-art semantic segmentation approaches and to explore the usefulness of our proposed method for other tasks such as detection or depth estimation.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper conclusion -->

<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{landgraf2024dudes,
      title={Dudes: Deep uncertainty distillation using ensembles for semantic segmentation},
      author={Landgraf, Steven and Wursthorn, Kira and Hillemann, Markus and Ulrich, Markus},
      journal={PFG--Journal of Photogrammetry, Remote Sensing and Geoinformation Science},
      volume={92},
      number={2},
      pages={101--114},
      year={2024},
      publisher={Springer}
      }
</code></pre>
    </div>
</section>
<!--End BibTex citation -->
  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

  </body>
  </html>
